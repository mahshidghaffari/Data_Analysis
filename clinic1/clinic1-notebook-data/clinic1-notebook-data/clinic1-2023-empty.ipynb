{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Placeholder for your name)\n",
    "\n",
    "(Placeholder for your i-number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50a40f10-f4b6-4dd3-b7aa-c63ed3ca3244"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Analysis\n",
    "\n",
    "# Clinic1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELIVERABLES (DEADLINE 17/February late night, wildcards possible)\n",
    "\n",
    "Instructions for the deliverable: \n",
    "\n",
    "* Make sure that you include a proper amount/mix of comments, results and code.\n",
    "\n",
    "* In the end, make sure that all cells are executed properly and everything you need to show is in your (execucted) notebook.\n",
    "\n",
    "* You are asked to deliver **only your executed notebook file, .ipnyb** and nothing else. Enjoy!\n",
    "\n",
    "* Honor code applies to these tasks. Only individual work should be submitted.\n",
    "\n",
    "* Data science is a collaborative activity. While you may talk with others about the clinic, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "introduction",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "\n",
    "By completing and delivering the clinic tasks you will know how to :\n",
    "\n",
    "* Load files and check their integrity\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Wrangle data for analysis\n",
    "* Parse columns in the dataframe to create new dataframe columns\n",
    "* Use EDA to learn more about your data\n",
    "* Create and interpret informative visualizations to explore the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Introduction to the Problem\n",
    "\n",
    "We would like to help a business man in the city of Rome (let's call this guy Pim). Pim wants to introduce a scooter rental system for people to drive around the city. He got some data from a pilot that was conducted in the city and now he would like to know more about the users and be able to draw insights from this data. \n",
    "\n",
    "In this clinic, you will perform tasks to clean, visualize, and explore the user data. You will also investigate open-ended questions. These open-ended questions ask you to think critically about how the plots you have created provide insight into the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 A note on the basic EDA workflow\n",
    "\n",
    "Before we move to the actual clinic tasks, a reminder about the basic EDA workflow:\n",
    "\n",
    "1. **Build** a DataFrame from the data (ideally, put all data in this object)\n",
    "2. **Clean** the DataFrame. It should have the following properties:\n",
    "    - Each row describes a single object\n",
    "    - Each column describes a property of that object\n",
    "    - Columns are numeric whenever appropriate\n",
    "    - Columns contain atomic properties that cannot be further decomposed\n",
    "3. Explore **global properties**. Use histograms, scatter plots, and aggregation functions to summarize the data.\n",
    "4. Explore **group properties**. Use groupby and small multiples to compare subsets of the data.\n",
    "\n",
    "This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Grading\n",
    "\n",
    "The clinic is broken down to several sub-questions so that they help you solve the tasks in an iterative way but also to facilitate grading. \n",
    "\n",
    "For responses that require numerical answers and some comment/discussion (free response), readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "For plots, you should abide to the basic principles as we have discussed in class. Note that for ALL plotting questions from here on out (also for other clinics), we will expect appropriate titles, axis labels, legends, etc. The following question serves as a good guideline on what is \"enough\": If I directly downloaded the plot and viewed it, would I be able to tell what was being visualized without knowing the question?\n",
    "\n",
    "\n",
    "### Score breakdown per sub-question\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "Question 1a | 2\n",
    "Question 1b | 1\n",
    "Question 1c | 2\n",
    "Question 1d | 4\n",
    "Question 2a | 2\n",
    "Question 2b | 2\n",
    "Question 2c | 1\n",
    "Question 2d | 1\n",
    "Question 2e | 2\n",
    "Question 2f | 2\n",
    "Question 3a | 5\n",
    "Question 3b | 3\n",
    "Question 4  | 3\n",
    "Question 5a | 2\n",
    "Question 5b | 2\n",
    "Question 6a | 1\n",
    "Question 6b | 4\n",
    "Question 6c | 3\n",
    "Question 6d | 2\n",
    "Question 7a | 4\n",
    "Question 7b | 4\n",
    "Total | 52\n",
    "\n",
    "Your final score out of 52 will be scaled down to 1 and be your final grade for this clinic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First things first\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "# Default plot configurations\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "codebook",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 0.3 Loading the data\n",
    "\n",
    "The data we are exploring is collected at a period between 2011-2012 in Rome.\n",
    "\n",
    "The variables in this data frame are defined as:\n",
    "\n",
    "Variable       | Description\n",
    "-------------- | ------------------------------------------------------------------\n",
    "instant | record index\n",
    "dteday | date\n",
    "season | 1. spring <br> 2. summer <br> 3. fall <br> 4. winter\n",
    "yr | year (0: 2011, 1:2012)\n",
    "mnth | month ( 1 to 12)\n",
    "hr | hour (0 to 23)\n",
    "holiday | whether day is holiday or not\n",
    "weekday | day of the week\n",
    "workingday | if day is neither weekend nor holiday\n",
    "weathersit | 1. clear or partly cloudy <br> 2. mist and clouds <br> 3. light snow or rain <br> 4. heavy rain or snow\n",
    "temp | normalized temperature in Celsius (divided by 41)\n",
    "atemp | normalized \"feels-like\" temperature in Celsius (divided by 50)\n",
    "hum | normalized percent humidity (divided by 100)\n",
    "windspeed| normalized wind speed (divided by 67)\n",
    "casual | count of casual users\n",
    "registered | count of registered users\n",
    "cnt | count of total users including casual and registered  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following code loads the data into a Pandas `DataFrame'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T05:50:18.144004Z",
     "start_time": "2018-09-12T05:50:18.094479Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "load-data-code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data.  No further action is needed\n",
    "full = pd.read_csv('data/clientnumbers.txt')\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0f8e3c0cc106c97",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Below, we show the shape of the file. You should see that the size of the DataFrame matches the number of lines in the file, minus the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ffa02efc2941b30c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 1: Data Preparation\n",
    "A few of the variables that are numeric/integer actually encode categorical data. These include `holiday`, `weekday`, `workingday`, and `weathersit`. In the following problem, we will convert these four variables to strings specifying the categories. In particular, use 3-letter labels (`Sun`, `Mon`, `Tue`, `Wed`, `Thu`, `Fri`, and `Sat`) for `weekday`. You may simply use `yes`/`no` for `holiday` and `workingday`. \n",
    "\n",
    "In this exercise we will *mutate* the data frame, **overwriting the corresponding variables in the data frame.** However, our notebook will effectively document this in-place data transformation for future readers. Make sure to leave the underlying datafile `clientnumbers.txt` unmodified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### Question 1a (Decoding `weekday`, `workingday`, and `weathersit`)\n",
    "\n",
    "Decode the `holiday`, `weekday`, `workingday`, and `weathersit` fields:\n",
    "\n",
    "1. `holiday`: Convert to `yes` and `no`.  Hint: There are fewer holidays...\n",
    "1. `weekday`: It turns out that Monday is the day with the most holidays.  Mutate the `'weekday'` column to use the 3-letter label (`'Sun'`, `'Mon'`, `'Tue'`, `'Wed'`, `'Thu'`, `'Fri'`, and `'Sat'` ...) instead of its current numerical values. Assume `0` corresponds to `Sun`, `1` to `Mon` and so on.\n",
    "1. `workingday`: Convert to `yes` and `no`.\n",
    "1. `weathersit`: You should replace each value with one of `Clear`, `Mist`, `Light`, or `Heavy`.\n",
    "\n",
    "**Note:** If you want to revert changes, run the cell that reloads the file.\n",
    "\n",
    "**Hint:**  One approach is to use the [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) method of the pandas DataFrame class. We haven't discussed how to do this so you'll need to look at the documentation. The most concise way is with the approach described in the documentation as \"nested-dictonaries\", though there are many possible solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code for 1a goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b (Holidays)\n",
    "\n",
    "How many entries in the data correspond to holidays?  Set the variable `num_holidays` to this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for 1b goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1c (Computing Daily Total Counts)\n",
    "\n",
    "The granularity of this data is at the hourly level.  However, for some of the analysis we will also want to compute daily statistics.  In particular, in the next few questions we will be analyzing the daily number of registered and unregistered users.\n",
    "\n",
    "Construct a data frame named `daily_counts` indexed by `dteday` with the following columns:\n",
    "* `casual`: total number of casual users for each day\n",
    "* `registered`: total number of registered users for each day\n",
    "* `workingday`: whether that day is a working day or not (`yes` or `no`)\n",
    "\n",
    "**Hint**: `groupby` and `agg`. For the `agg` method, please check the [documentation](https://pandas.pydata.org/docs/reference/groupby.html) for examples on applying different aggregations per column. If you use the capability to do different aggregations by column, you can do this task with a single call to `groupby` and `agg`. For the `workingday` column we can take any of the values since we are grouping by the day, thus the value will be the same within each group. Take a look at the `'first'` or `'last'` aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###code for 1c goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1d (Identifying issues with the data)\n",
    "\n",
    "Inspect the variables (based on the codebook) and identify potential issues with one (or more) of them. Think about missing values, mistakes, outliers, errors etc. Correct these and justify your answers accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###code for 1d goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 2: Exploring the Distribution of Users\n",
    "\n",
    "Let's begin by comparing the distribution of the daily counts of casual and registered users. The following questions require some heavy plotting. Below we are summarizing some functions (should be updated on the latest versions). \n",
    "\n",
    "### Matplotlib and Seaborn Table of Common Functions\n",
    "\n",
    "`x` and `y` are sequences of values (i.e. arrays, lists, or Series).\n",
    "\n",
    "| Function | Description |\n",
    "| -------- | ----------- |\n",
    "| `plt.plot(x, y)` | Creates a line plot of `x` against `y` |\n",
    "| `plt.title(name)` | Adds a title `name` to the current plot |\n",
    "| `plt.xlabel(name)` | Adds a label `name` to the x-axis |\n",
    "| `plt.ylabel(name)` | Adds a label `name` to the y-axis |\n",
    "| `plt.scatter(x, y)` | Creates a scatter plot of `x` against `y` |\n",
    "| `plt.hist(x, bins=None)` | Creates a histogram of `x`; `bins` can be an integer or a sequence |\n",
    "| `plt.bar(x, height)` | Creates a bar plot of categories `x` and corresponding heights `height` |\n",
    "| `sns.histplot(data, x, y, hue, kde)` | Creates a distribution plot; `data` is a DataFrame; `x`, `y` are column names in `data` that specify positions on the x and y axes; `hue` is a column name in `data` that adds subcategories to the plot based on `hue`; `kde` is a boolean that determines whether to overlay a KDE curve |\n",
    "|`sns.lineplot(data, x, y, hue)` | Creates a line plot |\n",
    "|`sns.scatterplot(data, x, y, hue, size)` | Creates a scatter plot; `size` is a vector that contains the size of point for each subcategory based on `hue` |\n",
    "|`sns.kdeplot(x, y)` |  Creates a kernel density estimate plot; `x`, `y` are series of data that indicate positions on the `x` and `y` axis |\n",
    "|`sns.jointplot(x, y, data, kind)` | Creates a joint plot of 2 variables with KDE plot in the middle and a distribution plot for each variable on the sides; `kind` determines the visualization type for the distribution plot, can be `scatter`, `kde` or `hist` |\n",
    "\n",
    "**Note**: This list of functions and parameters is **not** exhaustive. You may need to reference and explore more documentation to answer the following questions, but we will help you through that process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "#### Question 2a\n",
    "\n",
    "Use the [`sns.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html#seaborn.histplot) function to create a plot that overlays the distribution of the daily counts of bike users, using blue to represent `casual` riders, and green to represent `registered` riders. The temporal granularity of the records should be daily counts, which you should have after completing question 1c.\n",
    "\n",
    "**Hint:** You will need to set the `stat` parameter appropriately to match the desired plot.\n",
    "\n",
    "Include a legend, xlabel, ylabel, and title. Read the [seaborn plotting tutorial](https://seaborn.pydata.org/tutorial/distributions.html) if you're not sure how to add these. After creating the plot, look at it and make sure you understand what the plot is actually telling us, e.g on a given day, the most likely number of registered riders we expect is ~4000, but it could be anywhere from nearly 0 to 7000.\n",
    "\n",
    "**Update 13/2: distplot is deprecated, work with displot or histplot instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for 2a goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b\n",
    "\n",
    "In the cell below, descibe the differences you notice between the density curves for casual and registered users.  Consider concepts such as modes, symmetry, skewness, tails, gaps and outliers.  Include a comment on the spread of the distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c\n",
    "\n",
    "In addition to the type of user (casual vs. registered) and the overall count of each, what other kinds of demographic data would be useful (e.g. identity, neighborhood, monetary expenses, etc.)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2d\n",
    "\n",
    "What is an example of a privacy or consent issue that could occur when accessing the demographic data you brought up in the previous question?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2e\n",
    "\n",
    "The density plots do not show us how the counts for registered and casual users vary together. Use [`sns.lmplot`](https://seaborn.pydata.org/generated/seaborn.lmplot.html) to make a scatter plot to investigate the relationship between casual and registered counts. This time, let's use the `full` DataFrame to plot hourly counts instead of daily counts.\n",
    "\n",
    "The `lmplot` function will also try to draw a linear regression line. Color the points in the scatterplot according to whether or not the day is working day. There are many points in the scatter plot so make them small to help reduce overplotting. Also make sure to set `fit_reg=True` to generate the linear regression line. You can set the `height` parameter if you want to adjust the size of the `lmplot`. Make sure to include a title.\n",
    "\n",
    "**Hints (updated):** \n",
    "* Checkout this helpful [tutorial on `lmplot`](https://seaborn.pydata.org/tutorial/regression.html).\n",
    "\n",
    "* You will need to set `x`, `y`, and `hue` and the `scatter_kws` in the `sns.lmplot` call.\n",
    "\n",
    "* You will need to call [`plt.title`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.title.html) to add a title for the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to 2e goes here\n",
    "\n",
    "# Depending on the setup, you might want to make the font size a bit bigger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2f\n",
    "\n",
    "What does this scatterplot seem to reveal about the relationship (if any) between casual and registered users and whether or not the day is a working day or not? What effect does [overplotting](https://www.displayr.com/what-is-overplotting/) have on your ability to describe this relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 3: Visualization\n",
    "\n",
    "### Question 3\n",
    "\n",
    "#### Question 3a Bivariate Kernel Density Plot\n",
    " \n",
    "To address overplotting, we will try visualizing the data with another technique, the bivariate kernel density estimate.\n",
    "\n",
    "You will want to read up on the documentation for `sns.kdeplot` which can be found at https://seaborn.pydata.org/generated/seaborn.kdeplot.html\n",
    "\n",
    "You can think of this plot as an overhead countour or topographical map, where the \"high\" regions are those with more data points, and \"low\" regions are those with fewer data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1572ce18192a0036",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "A basic kde plot of all the data is quite easy to generate. However, this plot includes data from working and non-working days, which isn't what we want. Check the code below for how to generate a simple KDE plot. Adjust any variable names, if you have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e177fd6f517469dd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=daily_counts, x='casual', y='registered')\n",
    "\n",
    "\n",
    "#deprecated (old) (update 13/2)\n",
    "#sns.kdeplot(daily_counts['casual'], daily_counts['registered'])\n",
    "#plt.title('KDE Plot Comparison of Registered vs Casual Users');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the plot with working and non-working days separated can be complicated so we will provide a walkthrough below, feel free to use whatever method you wish however if you do not want to follow the walkthrough.\n",
    "\n",
    "**Hints (updated):** \n",
    "* You can use `loc` with a boolean array and column names at the same time\n",
    "* You will need to call kdeplot twice, each time drawing different data from the `daily_counts` table.\n",
    "* Check out this [guide](https://matplotlib.org/stable/tutorials/introductory/usage.html) to see an example of how to create a legend. In particular, look at how the example in the guide makes use of the `label` argument in the call to `plt.plot()` and what the `plt.legend()` call does. This is a good exercise to learn how to use examples to get the look you want.\n",
    "* You will want to set the `cmap` parameter of `kdeplot` to `\"Reds\"` and `\"Blues\"` (or whatever two contrasting colors you'd like), and also set the `label` parameter to address which type of day you want to plot. You are required for this question to use two sets of contrasting colors for your plots.\n",
    "\n",
    "After you get your plot working, experiment by setting `shade=True` in `kdeplot` to see the difference between the shaded and unshaded version. Please submit your work with `shade=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to 3a goes here\n",
    "\n",
    "# Set the figure size for the plot\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Set 'is_workingday' to a boolean array that is true for all working_days\n",
    "is_workingday = ...\n",
    "\n",
    "# Bivariate KDEs require two data inputs. \n",
    "# In this case, we will need the daily counts for casual and registered riders on workdays\n",
    "# Hint: consider using the .loc method here.\n",
    "casual_workday = ...\n",
    "registered_workday = ...\n",
    "\n",
    "# Use sns.kdeplot on the two variables above to plot the bivariate KDE for weekday rides\n",
    "...\n",
    "\n",
    "not_workingday = ...\n",
    "# Repeat the same steps above but for rows corresponding to non-workingdays\n",
    "# Hint: Again, consider using the .loc method here.\n",
    "casual_non_workday = ...\n",
    "registered_non_workday = ...\n",
    "\n",
    "# Use sns.kdeplot on the two variables above to plot the bivariate KDE for non-workingday rides\n",
    "...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b\n",
    "\n",
    "What additional details can you identify from this contour plot that were difficult to determine from the scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Joint Plot\n",
    "\n",
    "As an alternative approach to visualizing the data, construct the following set of three plots where the main plot shows the contours of the kernel density estimate of daily counts for registered and casual users plotted together, and the two \"margin\" plots (at the top and right of the figure) provide the univariate kernel density estimate of each of these variables. Note that this plot makes it harder see the linear relationships between casual and registered for the two different conditions (working day vs. non-working day).\n",
    "\n",
    "**Hints (updated)**:\n",
    "* The [seaborn plotting tutorial](https://seaborn.pydata.org/tutorial/distributions.html) has examples that may be helpful.\n",
    "* Take a look at `sns.jointplot` and its `kind` parameter.\n",
    "* `set_axis_labels` can be used to rename axes on the contour plot.\n",
    "\n",
    "**Note**:\n",
    "* At the end of the cell, we called `plt.suptitle` to set a custom location for the title.\n",
    "* We also can call `plt.subplots_adjust(top=0.9)` in case your title overlaps with your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for 4 goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5: Understanding Daily Patterns\n",
    "\n",
    "### Question 5\n",
    "\n",
    "#### Question 5a\n",
    "Let's examine the behavior of users by plotting the average number of users for each hour of the day over the **entire dataset**, stratified by user type. Here, two line plots in the same figure should be okay (pay attention to proper labeling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer to 5a goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5b\n",
    "\n",
    "What can you observe from the plot?  Hypothesize about the meaning of the peaks in the registered users' distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6: Exploring Users and Weather\n",
    "\n",
    "Now let's examine how the weather is affecting user' behavior. First let's look at how the proportion of casual user changes as weather changes.\n",
    "\n",
    "### Question 6\n",
    "\n",
    "#### Question 6a\n",
    "Create a new column `prop_casual` in the `full` DataFrame representing the proportion of casual users out of all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer to 6a goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 6b\n",
    "In order to examine the relationship between proportion of casual users and temperature, we can create a scatterplot using `sns.scatterplot`. We can even use color/hue to encode the information about day of week. Run the cell below (or adapt it if you have renamed any variables) and then comment on its explainability.\n",
    "\n",
    "**Hint**: You will need to set the `data`, `x`, `y`, and `hue` in the `sns.scatterplot` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-728459bdb0b60604",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=full, x=\"temp\", y=\"prop_casual\", hue=\"weekday\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you comment on this figure? Mention any problems you see. How would you think of approaching this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-980b34b254817347",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "A better approach is to use local smoothing. The basic idea is that for each x value, we compute some sort of representative y value that captures the data close to that x value. One technique for local smoothing is \"Locally Weighted Scatterplot Smoothing\" or LOWESS. An example is below. The green curve shown is a smoothed version of the scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T05:50:28.793327Z",
     "start_time": "2018-09-12T05:50:28.646991Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fae506cbd94f98bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#updated 13/2\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "# Make noisy data\n",
    "xobs = np.sort(np.random.rand(100)*4.0 - 2)\n",
    "yobs = np.exp(xobs) + np.random.randn(100) / 2.0\n",
    "sns.scatterplot(x=xobs, y=yobs, label=\"Raw Data\")\n",
    "\n",
    "# Predict 'smoothed' valued for observations\n",
    "ysmooth = lowess(yobs, xobs, return_sorted=False)\n",
    "sns.lineplot(x=xobs, y=ysmooth, label=\"Smoothed Estimator\", color='red')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case with the users' data, we want 7 curves, one for each day of the week. The x-axis will be the temperature and the y-axis will be a smoothed version of the proportion of casual users.\n",
    "\n",
    "You should use [`statsmodels.nonparametric.smoothers_lowess.lowess`](http://www.statsmodels.org/dev/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html) just like the example above. Unlike the example above, plot ONLY the lowess curve. Do not plot the actual data, which would result in overplotting. For this problem, the simplest way is to use a loop.\n",
    "\n",
    "**Hints:** \n",
    "* Start by just plotting only one day of the week to make sure you can do that first.\n",
    "\n",
    "* The `lowess` function expects y coordinate first, then x coordinate. You should also set the `return_sorted` field to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "#your code for 6b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6c\n",
    "\n",
    "What do you see from the curve plot? How is `prop_casual` changing as a function of temperature? Do you notice anything else interesting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6d\n",
    "\n",
    "Based on the data you have explored (distribution of users, daily patterns, weather, additional data/information you have seen), do you think this scooter user info should be realistically scaled across other cities in Italy. Why or why not? Justify your answer as a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** fancy answer goes here ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7a. Compute Something Interesting\n",
    "\n",
    "Play with the data and try to compute something interesting about the data. Please try to use at least one of groupby, pivot, or merge (or all of the above).  \n",
    "\n",
    "Please show your work in the cell below and describe in words what you found in the same cell. This question will be graded leniently but good solutions may be used to create future clinics.\n",
    "\n",
    "#### Grading ####\n",
    "\n",
    "Since the question is more open ended, we will have a more relaxed rubric, classifying your answers into the following three categories:\n",
    "\n",
    "- **Great** (4 points): Uses a combination of pandas operations (such as groupby, pivot, merge) to answer a relevant question about the data. The text description provides a reasonable interpretation of the result.\n",
    "- **Passing** (1-3 points): Computation is flawed or very simple. The text description is incomplete but makes some sense.\n",
    "- **Unsatisfactory** (0 points): No computation is performed, or a computation with completely wrong results.\n",
    "\n",
    "\n",
    "***Put your code in one cell below and your explanation in a markdown cell below***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code for 7a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** explanation goes here ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7b. Create some more cool visualizations!\n",
    "\n",
    "Play with the data, and try to produce some visualizations to answer one question that you find interesting regarding the data. You might want to use `merge`/`groupby`/`pivot` to process the data before creating visualizations.\n",
    "\n",
    "Please show your work in the cells below (feel free to use extra cells if you want), and describe in words what you found. This question will be graded leniently, but good solutions may be used to create future clinic problems. \n",
    "\n",
    "\n",
    "#### Grading ####\n",
    "\n",
    "Since the question is more open ended, we will have a more relaxed rubric, classifying your answers into the following three categories:\n",
    "\n",
    "- **Great** (4 points): The chart is well designed, and the data computation is correct. The text written articulates a reasonable metric and correctly describes the relevant insight and answer to the question you are interested in.\n",
    "- **Passing** (1-3 points): A chart is produced but with some flaws such as bad encoding. The text written is incomplete but makes some sense.\n",
    "- **Unsatisfactory** (0 points): No chart is created, or a chart with completely wrong results.\n",
    "\n",
    "You should have the following in your answers:\n",
    "* a few visualizations; Please limit your visualizations to 5 plots.\n",
    "* a few sentences (not too long please!)\n",
    "\n",
    "***Put your code in one cell below and your explanation in a markdown cell below***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code for 7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** explanation goes here ***\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
